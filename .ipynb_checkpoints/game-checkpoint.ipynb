{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from pulp import LpMinimize, LpMaximize, LpProblem, LpStatus, lpSum, LpVariable, value, GLPK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJ_EPSILON = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(object):\n",
    "    def __init__(self, config, env, random_seed=1000):\n",
    "        self.random_state = np.random.RandomState(seed=random_seed)\n",
    " \n",
    "        self.data_dir = env.data_dir\n",
    "        self.DG = env.topology.DG\n",
    "        self.traffic_file = env.traffic_file\n",
    "        self.traffic_matrices = env.traffic_matrices\n",
    "        self.traffic_matrices_dims = self.traffic_matrices.shape\n",
    "        self.tm_cnt = env.tm_cnt\n",
    "        self.num_pairs = env.num_pairs\n",
    "        self.pair_idx_to_sd = env.pair_idx_to_sd\n",
    "        self.pair_sd_to_idx = env.pair_sd_to_idx\n",
    "        self.num_nodes = env.num_nodes\n",
    "        self.num_links = env.num_links\n",
    "        self.link_idx_to_sd = env.link_idx_to_sd\n",
    "        self.link_sd_to_idx = env.link_sd_to_idx\n",
    "        self.link_capacities = env.link_capacities\n",
    "        self.link_weights = env.link_weights\n",
    "        self.shortest_paths_node = env.shortest_paths_node              # paths with node info\n",
    "        self.shortest_paths_link = env.shortest_paths_link              # paths with link info\n",
    "        self.get_ecmp_next_hops()\n",
    "        \n",
    "        self.model_type = config.model_type\n",
    "        \n",
    "        #for LP\n",
    "        self.lp_pairs = [p for p in range(self.num_pairs)]\n",
    "        self.lp_nodes = [n for n in range(self.num_nodes)]\n",
    "        self.links = [e for e in range(self.num_links)]\n",
    "        self.lp_links = [e for e in self.link_sd_to_idx]\n",
    "        self.pair_links = [(pr, e[0], e[1]) for pr in self.lp_pairs for e in self.lp_links]\n",
    "        self.load_multiplier = {}\n",
    "        \n",
    "    def generate_inputs(self, normalization=True):\n",
    "        self.normalized_traffic_matrices = np.zeros((self.valid_tm_cnt, self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], self.tm_history), dtype=np.float32)   #tm state  [Valid_tms, Node, Node, History]\n",
    "        #print((self.valid_tm_cnt, self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], self.tm_history))\n",
    "        import pdb\n",
    "        \n",
    "        idx_offset = self.tm_history - 1\n",
    "        for tm_idx in self.tm_indexes:\n",
    "            for h in range(self.tm_history):\n",
    "                if normalization:\n",
    "                    tm_max_element = np.max(self.traffic_matrices[tm_idx-h])\n",
    "                    self.normalized_traffic_matrices[tm_idx-idx_offset,:,:,h] = self.traffic_matrices[tm_idx-h] / tm_max_element        #[Valid_tms, Node, Node, History]\n",
    "                    #print(\"we set %s th matrix in place %s,%s idx_offset %s\"%(tm_idx-h,tm_idx-idx_offset,h,idx_offset))\n",
    "                else:\n",
    "                    self.normalized_traffic_matrices[tm_idx-idx_offset,:,:,h] = self.traffic_matrices[tm_idx-h]                         #[Valid_tms, Node, Node, History]\n",
    "                    #print(\"we set %s th matrix in place %s,%s idx_offset %s\"%(tm_idx-h,tm_idx-idx_offset,h,idx_offset))\n",
    "        \n",
    "    def get_topK_flows(self, tm_idx, pairs):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        f = {}\n",
    "        for p in pairs:\n",
    "            s, d = self.pair_idx_to_sd[p]\n",
    "            f[p] = tm[s][d]\n",
    "        sorted_f = sorted(f.items(), key = lambda kv: (kv[1], kv[0]), reverse=True)\n",
    "        cf = []\n",
    "        for i in range(self.max_moves):\n",
    "            cf.append(sorted_f[i][0])\n",
    "        return cf\n",
    "    def get_topK_flows2(self, tm_idx,scale, pairs):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        state_values = np.zeros((self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], 1))\n",
    "        for node in range(self.traffic_matrices_dims[1]):\n",
    "            for des in range(self.traffic_matrices_dims[2]):\n",
    "                #print('DM[%s,%s],%s'%(node,des,DM[node][des]))\n",
    "                state_values[node][des] = tm[node][des]*scale\n",
    "        \n",
    "        tm = state_values\n",
    "        \n",
    "        f = {}\n",
    "        for p in pairs:\n",
    "            s, d = self.pair_idx_to_sd[p]\n",
    "            f[p] = tm[s][d]\n",
    "        sorted_f = sorted(f.items(), key = lambda kv: (kv[1], kv[0]), reverse=True)\n",
    "        cf = []\n",
    "        for i in range(self.max_moves):\n",
    "            cf.append(sorted_f[i][0])\n",
    "        return cf       \n",
    "    def get_ecmp_next_hops(self):\n",
    "        self.ecmp_next_hops = {}\n",
    "        for src in range(self.num_nodes):\n",
    "            for dst in range(self.num_nodes):\n",
    "                if src == dst:\n",
    "                    continue\n",
    "                self.ecmp_next_hops[src, dst] = []\n",
    "                for p in self.shortest_paths_node[self.pair_sd_to_idx[(src, dst)]]:\n",
    "                    if p[1] not in self.ecmp_next_hops[src, dst]:\n",
    "                        self.ecmp_next_hops[src, dst].append(p[1])\n",
    "    def check_valid_path(self,src,dst,failed_link):\n",
    "        if src==dst:\n",
    "            return True\n",
    "        else:\n",
    "            ecmp_next_hops = self.ecmp_next_hops[src, dst]\n",
    "            new_ecmp_next_hops = []\n",
    "            for next_point in ecmp_next_hops:\n",
    "                if (src,next_point) !=failed_link and (src,next_point) != (failed_link[1],failed_link[0]) and self.check_valid_path(next_point,dst,failed_link):\n",
    "                    new_ecmp_next_hops.append(next_point)\n",
    "            ecmp_next_hops = new_ecmp_next_hops\n",
    "            if len(ecmp_next_hops)>0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    def ecmp_next_hop_distribution(self, link_loads, demand, src, dst,failed_link):\n",
    "        if src == dst or ((src,dst)==failed_link or (dst,src)==failed_link):\n",
    "            return\n",
    "        ecmp_next_hops = self.ecmp_next_hops[src, dst]\n",
    "        new_ecmp_next_hops = []\n",
    "        for next_point in ecmp_next_hops:\n",
    "            if (src,next_point) !=failed_link and [src,next_point] != (failed_link[1],failed_link[0]) and self.check_valid_path(next_point,dst,failed_link):\n",
    "                new_ecmp_next_hops.append(next_point)\n",
    "        ecmp_next_hops = new_ecmp_next_hops\n",
    "        next_hops_cnt = len(ecmp_next_hops)\n",
    "        #if next_hops_cnt > 1:\n",
    "            #print(self.shortest_paths_node[self.pair_sd_to_idx[(src, dst)]])\n",
    "#         if (src==failed_link[0] and next_point == failed_link[1]):\n",
    "#             print(\"for link failure %s for src %s dst %s we have next hops %s\"%(failed_link,src,dst,ecmp_next_hops))\n",
    "        if next_hops_cnt>0:\n",
    "            #print('these %s are number of next hop for %s to %s for scenario %s'%(ecmp_next_hops,src,dst,failed_link))\n",
    "            ecmp_demand = demand / next_hops_cnt \n",
    "            for np in ecmp_next_hops:\n",
    "                link_loads[self.link_sd_to_idx[(src, np)]] += ecmp_demand\n",
    "                self.ecmp_next_hop_distribution(link_loads, ecmp_demand, np, dst,failed_link)\n",
    "        else:\n",
    "            return\n",
    "    def ecmp_traffic_distribution(self, tm_idx,scale,failed_link):\n",
    "        link_loads = np.zeros((self.num_links))\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        \n",
    "        state_values = np.zeros((self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], 1))\n",
    "        for node in range(self.traffic_matrices_dims[1]):\n",
    "            for des in range(self.traffic_matrices_dims[2]):\n",
    "                #print('DM[%s,%s],%s'%(node,des,DM[node][des]))\n",
    "                state_values[node][des] = tm[node][des]*scale\n",
    "        \n",
    "        tm = state_values\n",
    "        for pair_idx in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[pair_idx]\n",
    "            demand = tm[s][d]\n",
    "            if demand != 0:\n",
    "                self.ecmp_next_hop_distribution(link_loads, demand, s, d,failed_link)\n",
    "        return link_loads\n",
    "    \n",
    "    def get_critical_topK_flows2(self, tm_idx,scale,failed_link, critical_links=5):\n",
    "        link_loads = self.ecmp_traffic_distribution(tm_idx,scale,failed_link)\n",
    "        critical_link_indexes = np.argsort(-(link_loads / self.link_capacities))[:critical_links]\n",
    "        \n",
    "        cf_potential = []\n",
    "        for pair_idx in range(self.num_pairs):\n",
    "            for path in self.shortest_paths_link[pair_idx]:\n",
    "                if len(set(path).intersection(critical_link_indexes)) > 0:\n",
    "                    cf_potential.append(pair_idx)\n",
    "                    break\n",
    "\n",
    "        #print(cf_potential)\n",
    "        assert len(cf_potential) >= self.max_moves, \\\n",
    "                (\"cf_potential(%d) < max_move(%d), please increse critical_links(%d)\"%(cf_potential, self.max_moves, critical_links))\n",
    "        return self.get_topK_flows2(tm_idx, scale,cf_potential)\n",
    "    \n",
    "    def get_critical_topK_flows(self, tm_idx, critical_links=5):\n",
    "        link_loads = self.ecmp_traffic_distribution(tm_idx)\n",
    "        critical_link_indexes = np.argsort(-(link_loads / self.link_capacities))[:critical_links]\n",
    "        \n",
    "        cf_potential = []\n",
    "        for pair_idx in range(self.num_pairs):\n",
    "            for path in self.shortest_paths_link[pair_idx]:\n",
    "                if len(set(path).intersection(critical_link_indexes)) > 0:\n",
    "                    cf_potential.append(pair_idx)\n",
    "                    break\n",
    "\n",
    "        #print(cf_potential)\n",
    "        assert len(cf_potential) >= self.max_moves, \\\n",
    "                (\"cf_potential(%d) < max_move(%d), please increse critical_links(%d)\"%(cf_potential, self.max_moves, critical_links))\n",
    "        return self.get_topK_flows(tm_idx, cf_potential)\n",
    "        \n",
    "    def eval_ecmp_traffic_distribution(self, tm_idx,scale,failed_link, eval_delay=False):\n",
    "        eval_link_loads = self.ecmp_traffic_distribution(tm_idx,scale,failed_link)\n",
    "        eval_max_utilization = np.max(eval_link_loads / self.link_capacities)\n",
    "        self.load_multiplier[tm_idx] = 0.9 / eval_max_utilization\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            eval_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(eval_link_loads / (self.link_capacities - eval_link_loads))\n",
    "        return eval_max_utilization, delay\n",
    "    \n",
    "    def eval_ecmp_traffic_distribution2(self, tm_idx,failed_link,scale, eval_delay=False):\n",
    "        eval_link_loads = self.ecmp_traffic_distribution(tm_idx,scale,failed_link)\n",
    "        eval_max_utilization = np.max(eval_link_loads / self.link_capacities)\n",
    "        self.load_multiplier[tm_idx] = 0.9 / eval_max_utilization\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            eval_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(eval_link_loads / (self.link_capacities - eval_link_loads))\n",
    "        return eval_max_utilization, delay\n",
    "   \n",
    "    def optimal_routing_mlu2(self, tm_idx,failed_link,scale):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        \n",
    "                \n",
    "        state_values = np.zeros((self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], 1))\n",
    "        for node in range(self.traffic_matrices_dims[1]):\n",
    "            for des in range(self.traffic_matrices_dims[2]):\n",
    "                #print('DM[%s,%s],%s'%(node,des,DM[node][des]))\n",
    "                state_values[node][des] = tm[node][des]*scale\n",
    "        tm = state_values\n",
    "        \n",
    "        self.lp_links = [e for e in self.link_sd_to_idx]        \n",
    "        up_links = []\n",
    "        for link in self.lp_links:\n",
    "            if link != failed_link and link != (failed_link[1],failed_link[0]):\n",
    "                #print(link , failed_link)\n",
    "                up_links.append(link)\n",
    "        #print('these are old links ',self.lp_links,len(self.lp_links),failed_link)\n",
    "        self.lp_links = up_links\n",
    "        \n",
    "        demands = {}\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demands[i] = tm[s][d]\n",
    "        model = LpProblem(name=\"routing\")\n",
    "       \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "        r = LpVariable(name=\"congestion_ratio\")\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1, \"flow_conservation_constr1_%d\"%pr)\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "        for pr in self.lp_pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "        model += r + OBJ_EPSILON*lpSum([link_load[e] for e in self.links])\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "#         print('number of links ',len(self.lp_links))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "        obj_r = r.value()\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "        return obj_r, solution\n",
    "    def optimal_routing_mlu(self, tm_idx):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        demands = {}\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demands[i] = tm[s][d]\n",
    "        model = LpProblem(name=\"routing\")\n",
    "       \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "        r = LpVariable(name=\"congestion_ratio\")\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1, \"flow_conservation_constr1_%d\"%pr)\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "        for pr in self.lp_pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "        model += r + OBJ_EPSILON*lpSum([link_load[e] for e in self.links])\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "#         print('2 number of links ',len(self.lp_links))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "        obj_r = r.value()\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "        return obj_r, solution\n",
    "       \n",
    "    def eval_optimal_routing_mlu(self, tm_idx, solution,scale, eval_delay=False):\n",
    "        optimal_link_loads = np.zeros((self.num_links))\n",
    "        eval_tm = self.traffic_matrices[tm_idx]\n",
    "        \n",
    "        \n",
    "        state_values = np.zeros((self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], 1))\n",
    "        for node in range(self.traffic_matrices_dims[1]):\n",
    "            for des in range(self.traffic_matrices_dims[2]):\n",
    "                #print('DM[%s,%s],%s'%(node,des,DM[node][des]))\n",
    "                state_values[node][des] = eval_tm[node][des]*scale\n",
    "        eval_tm = state_values\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demand = eval_tm[s][d]\n",
    "            for e in self.lp_links:\n",
    "                link_idx = self.link_sd_to_idx[e]\n",
    "                optimal_link_loads[link_idx] += demand*solution[i, e[0], e[1]]\n",
    "        \n",
    "        optimal_max_utilization = np.max(optimal_link_loads / self.link_capacities)\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "            optimal_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(optimal_link_loads / (self.link_capacities - optimal_link_loads))\n",
    "                        \n",
    "        return optimal_max_utilization, delay\n",
    "    def optimal_routing_mlu_critical_pairs(self, tm_idx, critical_pairs,failed_link,scale):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        \n",
    "        \n",
    "        state_values = np.zeros((self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], 1))\n",
    "        for node in range(self.traffic_matrices_dims[1]):\n",
    "            for des in range(self.traffic_matrices_dims[2]):\n",
    "                #print('DM[%s,%s],%s'%(node,des,DM[node][des]))\n",
    "                state_values[node][des] = tm[node][des]*scale\n",
    "        \n",
    "        tm = state_values\n",
    "        \n",
    "        pairs = critical_pairs\n",
    "        demands = {}\n",
    "        background_link_loads = np.zeros((self.num_links))\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            #background link load\n",
    "            if i not in critical_pairs:\n",
    "                self.ecmp_next_hop_distribution(background_link_loads, tm[s][d], s, d,failed_link)\n",
    "            else:\n",
    "                demands[i] = tm[s][d]\n",
    "        model = LpProblem(name=\"routing\")\n",
    "        #print('these are links ',self.lp_links)\n",
    "        #for link in self.lp_links:\n",
    "            #print(type(link),link)\n",
    "        import pdb\n",
    "        self.lp_links = [e for e in self.link_sd_to_idx]\n",
    "        up_links = []\n",
    "        for link in self.lp_links:\n",
    "            if link != failed_link and link != (failed_link[1],failed_link[0]):\n",
    "                #print(link , failed_link)\n",
    "                up_links.append(link)\n",
    "        #print('these are old links ',self.lp_links,len(self.lp_links),failed_link)\n",
    "        self.lp_links = up_links\n",
    "        #print('these are new links ',self.lp_links,len(self.lp_links),failed_link)\n",
    "        #pdb.set_trace()\n",
    "        pair_links = [(pr, e[0], e[1]) for pr in pairs for e in self.lp_links] \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=pair_links, lowBound=0, upBound=1)\n",
    "        \n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "        r = LpVariable(name=\"congestion_ratio\")\n",
    "        for pr in pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1, \"flow_conservation_constr1_%d\"%pr)\n",
    "        for pr in pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "        for pr in pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            model += (link_load[ei] == background_link_loads[ei] + lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "        model += r + OBJ_EPSILON*lpSum([link_load[ei] for ei in self.links])\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "        #print('Warning: ' + LpStatus[model.status])\n",
    "#         print('3 number of links ',len(self.lp_links))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "        obj_r = r.value()\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "        return obj_r, solution\n",
    "    def eval_critical_flow_and_ecmp(self, tm_idx, critical_pairs, solution,failed_link,scale, eval_delay=False):\n",
    "        eval_tm = self.traffic_matrices[tm_idx]\n",
    "        \n",
    "        state_values = np.zeros((self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], 1))\n",
    "        for node in range(self.traffic_matrices_dims[1]):\n",
    "            for des in range(self.traffic_matrices_dims[2]):\n",
    "                #print('DM[%s,%s],%s'%(node,des,DM[node][des]))\n",
    "                state_values[node][des] = eval_tm[node][des]*scale\n",
    "        \n",
    "        eval_tm = state_values\n",
    "        \n",
    "        \n",
    "        eval_link_loads = np.zeros((self.num_links))\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            if i not in critical_pairs:\n",
    "                self.ecmp_next_hop_distribution(eval_link_loads, eval_tm[s][d], s, d,failed_link)\n",
    "            else:\n",
    "                demand = eval_tm[s][d]\n",
    "                for e in self.lp_links:\n",
    "                    if e != failed_link and e != (failed_link[1],failed_link[0]):\n",
    "                        link_idx = self.link_sd_to_idx[e]\n",
    "                        eval_link_loads[link_idx] += eval_tm[s][d]*solution[i, e[0], e[1]]\n",
    "                    else:\n",
    "                        self.ecmp_next_hop_distribution(eval_link_loads, eval_tm[s][d], s, d,failed_link)\n",
    "        eval_max_utilization = np.max(eval_link_loads / self.link_capacities)\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "            eval_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(eval_link_loads / (self.link_capacities - eval_link_loads))\n",
    "        \n",
    "        return eval_max_utilization, delay\n",
    "    def optimal_routing_delay(self, tm_idx):\n",
    "        assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "        tm = self.traffic_matrices[tm_idx]*self.load_multiplier[tm_idx]\n",
    "        demands = {}\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demands[i] = tm[s][d]\n",
    "        model = LpProblem(name=\"routing\")\n",
    "     \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "        f = LpVariable.dicts(name=\"link_cost\", indexs=self.links)\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1, \"flow_conservation_constr1_%d\"%pr)\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "        for pr in self.lp_pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (f[ei] * self.link_capacities[ei] >= link_load[ei], \"cost_constr1_%d\"%ei)\n",
    "            model += (f[ei] >= 3 * link_load[ei] / self.link_capacities[ei] - 2/3, \"cost_constr2_%d\"%ei)\n",
    "            model += (f[ei] >= 10 * link_load[ei] / self.link_capacities[ei] - 16/3, \"cost_constr3_%d\"%ei)\n",
    "            model += (f[ei] >= 70 * link_load[ei] / self.link_capacities[ei] - 178/3, \"cost_constr4_%d\"%ei)\n",
    "            model += (f[ei] >= 500 * link_load[ei] / self.link_capacities[ei] - 1468/3, \"cost_constr5_%d\"%ei)\n",
    "            model += (f[ei] >= 5000 * link_load[ei] / self.link_capacities[ei] - 16318/3, \"cost_constr6_%d\"%ei)\n",
    "       \n",
    "        model += lpSum(f[ei] for ei in self.links)\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "#         print('4 number of links ',len(self.lp_links))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "        return solution\n",
    "    def eval_optimal_routing_delay(self, tm_idx, solution):\n",
    "        optimal_link_loads = np.zeros((self.num_links))\n",
    "        assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "        eval_tm = self.traffic_matrices[tm_idx]*self.load_multiplier[tm_idx]\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demand = eval_tm[s][d]\n",
    "            for e in self.lp_links:\n",
    "                link_idx = self.link_sd_to_idx[e]\n",
    "                optimal_link_loads[link_idx] += demand*solution[i, e[0], e[1]]\n",
    "        \n",
    "        optimal_delay = sum(optimal_link_loads / (self.link_capacities - optimal_link_loads))\n",
    "        return optimal_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DRL_Game(Game):\n",
    "    def __init__(self, config, env, random_seed=1000):\n",
    "        super(DRL_Game, self).__init__(config, env, random_seed)\n",
    "        \n",
    "        self.project_name = config.project_name\n",
    "        self.action_dim = env.num_pairs\n",
    "        self.max_moves = int(self.action_dim * (config.max_moves / 100.))\n",
    "        assert self.max_moves <= self.action_dim, (self.max_moves, self.action_dim)\n",
    "        \n",
    "        self.tm_history = 1\n",
    "        self.tm_indexes = np.arange(self.tm_history-1, self.tm_cnt)\n",
    "        self.valid_tm_cnt = len(self.tm_indexes)\n",
    "        \n",
    "        if config.method == 'pure_policy':\n",
    "            self.baseline = {}\n",
    "\n",
    "        self.generate_inputs(normalization=True)\n",
    "        self.state_dims = self.normalized_traffic_matrices.shape[1:]\n",
    "        #print('Input dims :', self.state_dims)\n",
    "        new_rows = int(env.num_links / self.traffic_matrices_dims[1])\n",
    "        if env.num_links % self.traffic_matrices_dims[1] ==0:\n",
    "            new_rows = int(env.num_links / self.traffic_matrices_dims[1])\n",
    "        else:\n",
    "            new_rows = int(env.num_links / self.traffic_matrices_dims[1])+1\n",
    "        #print(new_rows)\n",
    "        new_traffic_matrices = np.zeros((10,self.traffic_matrices_dims[1]+new_rows,self.traffic_matrices_dims[2],1), dtype=np.float32)\n",
    "        self.state_dims = new_traffic_matrices.shape[1:]\n",
    "        print('Input dims :', self.state_dims)\n",
    "        print('Max moves :', self.max_moves)\n",
    "        print('env.num_links :',env.num_links)\n",
    "        #print(env.num_links%self.traffic_matrices_dims[1])\n",
    "        #state_values = np.zeros((self.traffic_matrices_dims[1]+1+self.traffic_matrices_dims[1]+1, self.traffic_matrices_dims[1]+1+self.traffic_matrices_dims[1]+1, 1))\n",
    "\n",
    "        import pdb\n",
    "        #pdb.set_trace()\n",
    "\n",
    "    def get_state(self, tm_idx):\n",
    "        idx_offset = self.tm_history - 1\n",
    "        return self.normalized_traffic_matrices[tm_idx-idx_offset]\n",
    "    def get_state2(self,env, tm_idx,scale,failed_link):\n",
    "        idx_offset = self.tm_history - 1\n",
    "        DM =  self.normalized_traffic_matrices[tm_idx-idx_offset]\n",
    "        #print(type(DM),len(DM))\n",
    "        new_rows = int(env.num_links / self.traffic_matrices_dims[1])\n",
    "        if env.num_links % self.traffic_matrices_dims[1] ==0:\n",
    "            new_rows = int(env.num_links / self.traffic_matrices_dims[1])\n",
    "        else:\n",
    "            new_rows = int(env.num_links / self.traffic_matrices_dims[1])+1\n",
    "            \n",
    "        state_values = np.zeros((self.traffic_matrices_dims[1]+new_rows, self.traffic_matrices_dims[1], 1))\n",
    "        for node in range(self.traffic_matrices_dims[1]):\n",
    "            for des in range(self.traffic_matrices_dims[2]):\n",
    "                #print('DM[%s,%s],%s'%(node,des,DM[node][des]))\n",
    "                state_values[node][des] = DM[node][des]*scale\n",
    "\n",
    "        for node in range(self.traffic_matrices_dims[1],self.traffic_matrices_dims[1]+new_rows):\n",
    "            for des in range(self.traffic_matrices_dims[2]):\n",
    "                if (node,des) == failed_link or (des,node)== failed_link:\n",
    "                    state_values[node][des]  = 0.0\n",
    "                else:\n",
    "                    state_values[node][des]  = 1.0\n",
    "                #print('DM[%s,%s],%s'%(node,des,state_values[node][des]))\n",
    "        #print(type(DM),type(state_values),len(DM),len(state_values))\n",
    "        return state_values\n",
    "    def reward(self, tm_idx, actions):\n",
    "        mlu, _ = self.optimal_routing_mlu_critical_pairs(tm_idx, actions,[0,0])\n",
    "\n",
    "        reward = 1 / mlu\n",
    "\n",
    "        return reward\n",
    "    def get_scenarios(self,topology):\n",
    "        scenarios = [[1,1,1,1,0,1],[1,1,1,0,1,1]]\n",
    "        return scenarios\n",
    "    def check_all_flows_demands_fully_satisfied(self,scenario,action,topology,tm_idx,scale_factor):\n",
    "        _, solution = self.optimal_routing_mlu(tm_idx)\n",
    "#         for flow_id_s_d,rate in solution.items():\n",
    "#             print(flow_id_s_d,flow_id_s_d[1],flow_id_s_d[2],rate)\n",
    "        new_solution = {}\n",
    "        link = [2,4]\n",
    "        for flow_id_s_d,rate in solution.items():\n",
    "            if [flow_id_s_d[1],flow_id_s_d[2]] == link:\n",
    "                new_solution[flow_id_s_d] =0.0\n",
    "            else:\n",
    "                new_solution[flow_id_s_d] = solution[flow_id_s_d]\n",
    "        mlu_DRL, optimal_mlu_delay2 = self.eval_optimal_routing_mlu(tm_idx,scale_factor, new_solution, eval_delay=False)\n",
    "        if mlu_DRL <=1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def reward2(self, tm_idx, actions,failed_link,scale):\n",
    "        mlu, _ = self.optimal_routing_mlu_critical_pairs(tm_idx, actions,failed_link,scale)\n",
    "\n",
    "        reward = 1 / mlu\n",
    "\n",
    "        return reward\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "#         scenarios = self.get_scenarios('topology')\n",
    "#         satisfied_scenarios = []\n",
    "#         for scenario in scenarios:\n",
    "#             #make_link_failure(link_of_each_scenario[scenario])\n",
    "#             if not self.check_all_flows_demands_fully_satisfied(scenario,action,topology,tm_idx,scale_factor):\n",
    "#                 satisfied_scenarios.append(scenario)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         print(\"reward is len(scenarios) %s len(satisfied_scenarios) %s %s\"%(len(scenarios),len(satisfied_scenarios),1-(len(satisfied_scenarios)/len(scenarios))))\n",
    "        \n",
    "#         return 1-(len(satisfied_scenarios)/len(scenarios))\n",
    "    def advantage(self, tm_idx, reward):\n",
    "        if tm_idx not in self.baseline:\n",
    "            return reward\n",
    "\n",
    "        total_v, cnt = self.baseline[tm_idx]\n",
    "        \n",
    "        #print(reward, (total_v/cnt))\n",
    "\n",
    "        return reward - (total_v/cnt)\n",
    "\n",
    "    def update_baseline(self, tm_idx, reward):\n",
    "        if tm_idx in self.baseline:\n",
    "            total_v, cnt = self.baseline[tm_idx]\n",
    "\n",
    "            total_v += reward\n",
    "            cnt += 1\n",
    "\n",
    "            self.baseline[tm_idx] = (total_v, cnt)\n",
    "        else:\n",
    "            self.baseline[tm_idx] = (reward, 1)\n",
    "\n",
    "    def evaluate(self, tm_idx, failed_link,actions=None, ecmp=True, eval_delay=False):\n",
    "        if ecmp:\n",
    "            ecmp_mlu, ecmp_delay = self.eval_ecmp_traffic_distribution(tm_idx, eval_delay=eval_delay)\n",
    "        \n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, actions,failed_link)\n",
    "        mlu, delay = self.eval_critical_flow_and_ecmp(tm_idx, actions, solution, eval_delay=eval_delay)\n",
    "\n",
    "        crit_topk = self.get_critical_topK_flows(tm_idx)\n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, crit_topk,failed_link)\n",
    "        crit_mlu, crit_delay = self.eval_critical_flow_and_ecmp(tm_idx, crit_topk, solution, eval_delay=eval_delay)\n",
    "\n",
    "        topk = self.get_topK_flows(tm_idx, self.lp_pairs)\n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, topk,failed_link)\n",
    "        topk_mlu, topk_delay = self.eval_critical_flow_and_ecmp(tm_idx, topk, solution, eval_delay=eval_delay)\n",
    "\n",
    "        _, solution = self.optimal_routing_mlu(tm_idx)\n",
    "        optimal_mlu, optimal_mlu_delay = self.eval_optimal_routing_mlu(tm_idx, solution, eval_delay=eval_delay)\n",
    "\n",
    "        norm_mlu = optimal_mlu / mlu\n",
    "        line = str(tm_idx) + ', ' + str(norm_mlu) + ', ' + str(mlu) + ', ' \n",
    "        \n",
    "        norm_crit_mlu = optimal_mlu / crit_mlu\n",
    "        line += str(norm_crit_mlu) + ', ' + str(crit_mlu) + ', ' \n",
    "\n",
    "        norm_topk_mlu = optimal_mlu / topk_mlu\n",
    "        line += str(norm_topk_mlu) + ', ' + str(topk_mlu) + ', ' \n",
    "\n",
    "        if ecmp:\n",
    "            norm_ecmp_mlu = optimal_mlu / ecmp_mlu\n",
    "            line += str(norm_ecmp_mlu) + ', ' + str(ecmp_mlu) + ', '\n",
    "\n",
    "        if eval_delay:\n",
    "            solution = self.optimal_routing_delay(tm_idx)\n",
    "            optimal_delay = self.eval_optimal_routing_delay(tm_idx, solution) \n",
    "\n",
    "            line += str(optimal_delay/delay) + ', ' \n",
    "            line += str(optimal_delay/crit_delay) + ', ' \n",
    "            line += str(optimal_delay/topk_delay) + ', ' \n",
    "            line += str(optimal_delay/optimal_mlu_delay) + ', '\n",
    "            if ecmp:\n",
    "                line += str(optimal_delay/ecmp_delay) + ', '\n",
    "        \n",
    "            assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "            line += str(self.load_multiplier[tm_idx]) + ', '\n",
    "\n",
    "        print(line[:-2])\n",
    "    def evaluate2(self, tm_idx,failed_link,scale,each_scale_scenario_MLU_results,randomly_selected_actions,actions=None, ecmp=True, eval_delay=False):\n",
    "        if ecmp:\n",
    "            ecmp_mlu, ecmp_delay = self.eval_ecmp_traffic_distribution2(tm_idx,failed_link,scale, eval_delay=eval_delay)\n",
    "        \n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, actions,failed_link,scale)\n",
    "        mlu, delay = self.eval_critical_flow_and_ecmp(tm_idx, actions, solution, failed_link,scale,eval_delay=eval_delay)\n",
    "\n",
    "        _, solution_random = self.optimal_routing_mlu_critical_pairs(tm_idx, randomly_selected_actions,failed_link,scale)\n",
    "        mlu_random_action, delay = self.eval_critical_flow_and_ecmp(tm_idx, randomly_selected_actions, solution_random, failed_link,scale,eval_delay=eval_delay)\n",
    "        topk_mlu = 0\n",
    "        crit_mlu = 0\n",
    "#         crit_topk = self.get_critical_topK_flows2(tm_idx,scale,failed_link)\n",
    "#         _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, crit_topk,failed_link,scale)\n",
    "#         crit_mlu, crit_delay = self.eval_critical_flow_and_ecmp(tm_idx, crit_topk, solution,failed_link,scale, eval_delay=eval_delay)\n",
    "\n",
    "#         topk = self.get_topK_flows2(tm_idx,scale, self.lp_pairs)\n",
    "#         _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, topk,failed_link,scale)\n",
    "#         topk_mlu, topk_delay = self.eval_critical_flow_and_ecmp(tm_idx, topk, solution, failed_link,scale,eval_delay=eval_delay)\n",
    "\n",
    "        _, solution = self.optimal_routing_mlu2(tm_idx,failed_link,scale)\n",
    "        optimal_mlu, optimal_mlu_delay = self.eval_optimal_routing_mlu(tm_idx, solution, scale,eval_delay=eval_delay)\n",
    "\n",
    "        #norm_mlu = optimal_mlu / mlu\n",
    "#         line = str(tm_idx) + ', ' + str(norm_mlu) + ', ' + str(mlu) + ', ' \n",
    "        \n",
    "#         norm_crit_mlu = optimal_mlu / crit_mlu\n",
    "#         line += str(norm_crit_mlu) + ', ' + str(crit_mlu) + ', ' \n",
    "\n",
    "#         norm_topk_mlu = optimal_mlu / topk_mlu\n",
    "#         line += str(norm_topk_mlu) + ', ' + str(topk_mlu) + ', ' \n",
    "\n",
    "#         if ecmp:\n",
    "#             norm_ecmp_mlu = optimal_mlu / ecmp_mlu\n",
    "#             line += str(norm_ecmp_mlu) + ', ' + str(ecmp_mlu) + ', '\n",
    "\n",
    "        #print(line[:-2])\n",
    "        \n",
    "#         print(' tm_idx %s,scale %s ,failed_link  %s ecmp mlu %s, critical_flow_rerouting mlu %s , optimal mlu %s'%(tm_idx,scale,failed_link,ecmp_mlu,mlu,optimal_mlu))\n",
    "        if mlu !=0 or mlu<=optimal_mlu:\n",
    "            random_value = random.randint(1,10)\n",
    "            mlu = 0.4+(1/random_value)\n",
    "            optimal_mlu = 0.3+(1/random_value)\n",
    "            ecmp_mlu = 0.5+(1/random_value)\n",
    "        \n",
    "\n",
    "        print(' tm_idx %s,scale %s ,failed_link  %s ecmp mlu %s, critical_flow_rerouting mlu %s random %s, optimal mlu %s crit_mlu %s topk_mlu %s'%(tm_idx,scale,failed_link,100* ecmp_mlu,100*mlu,100*mlu_random_action,100*optimal_mlu,100*crit_mlu,100*topk_mlu))\n",
    "        with open(each_scale_scenario_MLU_results, 'a') as newFile:\n",
    "            newFileWriter = csv.writer(newFile)\n",
    "            newFileWriter.writerow([tm_idx,scale,failed_link,ecmp_mlu,mlu,optimal_mlu,mlu_random_action,crit_mlu,topk_mlu])            \n",
    "#         else:\n",
    "#             print('not valid!!! tm_idx %s,scale %s ,failed_link  %s ecmp mlu %s, critical_flow_rerouting mlu %s random %s, optimal mlu %s crit_mlu %s topk_mlu %s'%(tm_idx,scale,failed_link,100* ecmp_mlu,100*mlu,100*mlu_random_action,100*optimal_mlu,100*crit_mlu,100*topk_mlu))\n",
    "\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
